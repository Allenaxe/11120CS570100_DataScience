{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Clustering </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:blue;font-size:30px;font-family:Microsoft JhengHei\"> 跟著做1開頭</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from importing necessary package\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import metrics # for evaluations\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons # for generating experimental data\n",
    "from sklearn.preprocessing import StandardScaler # for feature scaling\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make matplotlib plot inline(Only in Ipython)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetrate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data\n",
    "#random_state is the seed used by random number generator for reproducibility(default=None)\n",
    "X, y = make_blobs(n_samples=10000,\n",
    "                 n_features=2,\n",
    "                 centers=3,\n",
    "                 random_state=111)\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data distributio using matplotlib \n",
    "#scatter(axis-x, axis-y, color)\n",
    "plt.scatter(X[:,0], X[:,1], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ground truth\n",
    "#scatter(axis-x, axis-y, color)\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Kmeans by random initial center </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform k-means on our data (train centroids)\n",
    "kmeans = KMeans(n_clusters=3,\n",
    "                n_init=3,\n",
    "                init='random',\n",
    "                tol=1e-4,\n",
    "                random_state=111,\n",
    "                verbose=True).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve predictions and cluster centeres(centroids)\n",
    "display(kmeans.labels_)\n",
    "display(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering result visualization with centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions\n",
    "plt.scatter(X[:,0], X[:,1], c=kmeans.labels_)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0],\n",
    "            kmeans.cluster_centers_[:,1],\n",
    "            c='w', marker='x', linewidths=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new data clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can make new predictions without re-run kmeans(simpily find nearest centroids)\n",
    "X_new = np.array([[10,10],[-10,-10],[-5,10]])\n",
    "y_pred = kmeans.predict(X_new)\n",
    "\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get distance from data point to every centroid\n",
    "kmeans.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:blue;font-size:30px;font-family:Microsoft JhengHei\"> 跟著做2開頭</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> k-means++ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perform k-means++ on our data\n",
    "kmeans_plus_plus = KMeans(n_clusters=3,\n",
    "                n_init=3,\n",
    "                init='k-means++',\n",
    "                tol=1e-4,\n",
    "                random_state=111,\n",
    "                verbose=True).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions\n",
    "plt.scatter(X[:,0], X[:,1], c=kmeans_plus_plus.labels_)\n",
    "plt.scatter(kmeans_plus_plus.cluster_centers_[:,0],\n",
    "            kmeans_plus_plus.cluster_centers_[:,1],\n",
    "            c='w', marker='x', linewidths=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:blue;font-size:30px;font-family:Microsoft JhengHei\"> 跟著做3開頭</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawback of Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawback1 : Need to choose the right “k”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate data with 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data.\n",
    "X, y = make_blobs(n_samples=1000,\n",
    "                 n_features=2,\n",
    "                 centers=3,\n",
    "                 random_state=170)\n",
    "#plot the data distribution\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:blue;font-size:24px;font-family:Microsoft JhengHei\">把n_cluster改為4, 5, 6試試</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try clustering data into k=x clusters, bad!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=2, random_state=111).fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:blue;font-size:30px;font-family:Microsoft JhengHei\"> 跟著做4開頭</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution : Measure Clustering Quality to Determine K\n",
    "### supervised method: 有ground turth ( homogenity, completeness)\n",
    "### unsupervised method: 無ground turth (silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics.completeness_score([1, 2, 3, 4], [1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data\n",
    "#this particular setting has one distinct cluster and 4 clusters placed close together\n",
    "X, y = make_blobs(n_samples=500,\n",
    "                 n_features=2,\n",
    "                 centers=4,\n",
    "                 cluster_std=1,\n",
    "                 center_box=(-10.0, 10.0),\n",
    "                 shuffle=True,\n",
    "                 random_state=1)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try k=2, 3, 4, 5, 6 clustering, and measuring cluster quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list of number of clusters\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "#for each number of clusters, perform silhouette analysis and visualize the results\n",
    "for n_clusters in range_n_clusters:\n",
    "    #perform kmeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    y_pred = kmeans.fit_predict(X)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
    "    plt.title(\"n_cluster = \"+str(n_clusters))\n",
    "    plt.show()\n",
    "    #compute the cluster homogeneity and completeness\n",
    "    homogenity = metrics.homogeneity_score(y, y_pred)\n",
    "    completeness = metrics.completeness_score(y, y_pred)\n",
    "    print(\"k=\", n_clusters, \"homogenity: \", homogenity)\n",
    "    print(\"k=\", n_clusters, \"completeness: \", completeness)\n",
    "    #compute the silhouette coefficient for each sameple\n",
    "    s = metrics.silhouette_samples(X, y_pred)\n",
    "    \n",
    "    #compute the mean silhouette coefficient of all the data points\n",
    "    s_mean = metrics.silhouette_score(X, y_pred)\n",
    "#     print(s_mean, sum(s) / len(s))\n",
    "\n",
    "    print(\"k=\", n_clusters, \"silhouette: \", s_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=10)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "#compute the cluster homogeneity and completeness\n",
    "homogenity = metrics.homogeneity_score(y, y_pred)\n",
    "completeness = metrics.completeness_score(y, y_pred)\n",
    "#compute the silhouette coefficient for each sameple\n",
    "s = metrics.silhouette_samples(X, y_pred)\n",
    "#compute the mean silhouette coefficient of all the data points\n",
    "s_mean = metrics.silhouette_score(X, y_pred)\n",
    "print(s_mean)\n",
    "index_0 = np.where(y_pred == 0)[0]\n",
    "s_0 = s[index_0]\n",
    "print('#number of cluster 0:',len(s_0))\n",
    "s_0_bigthan_smean = s_0[np.where(s_0 > s_mean)[0]]\n",
    "print('#number of data points whose s > s_mean and belong to cluster 0:',len(s_0_bigthan_smean))\n",
    "index_1 = np.where(y_pred == 1)[0]\n",
    "s_1 = s[index_1]\n",
    "print('#number of cluster 1:',len(s_1))\n",
    "s_1_bigthan_smean = s_1[np.where(s_1 > s_mean)[0]]\n",
    "print('#number of data points whose s > s_mean and belong to cluster 1:',len(s_1_bigthan_smean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"color:blue;font-size:30px;font-family:Microsoft JhengHei\"> 跟著做5開頭</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawback2 : Cannot Handle Noise Data and Outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data\n",
    "#this particular setting has one distinct cluster and 3 clusters placed close together\n",
    "X, y = make_blobs(n_samples=500,\n",
    "                 n_features=2,\n",
    "                 centers=4,\n",
    "                 cluster_std=1,\n",
    "                 center_box=(-10.0, 10.0),\n",
    "                 shuffle=True,\n",
    "                 random_state=1)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.title('ground truth')\n",
    "plt.show()\n",
    "#perform k-means on our data (train centroids)\n",
    "kmeans = KMeans(n_clusters=4, random_state=10)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
    "plt.title('clustering result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect outliers by threshold(mean distance of each cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio for our distance threshold, controlling how many outliers we want to detect\n",
    "distance_threshold_ratio = 2.0\n",
    "#plot the prediction sane as the above\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
    "\n",
    "#for each ith cluster, i=0-3(we have 4 clusters in this example)\n",
    "for i in [0, 1, 2, 3]:\n",
    "    #retrieve the indexs of data points belong to the ith cluster\n",
    "    indexs_of_X_in_ith_cluster = np.where(y_pred == i)[0]\n",
    "                                                       \n",
    "    #retrieve the data points by the indexs\n",
    "    X_in_ith_cluster = X[indexs_of_X_in_ith_cluster]\n",
    "                                                           \n",
    "    #retrieve the centroid\n",
    "    centroid = kmeans.cluster_centers_[i]\n",
    "    \n",
    "    # compute distance between data points and the centroid\n",
    "    distances = metrics.pairwise.euclidean_distances(X_in_ith_cluster, centroid.reshape(1,-1))\n",
    "    distance_threshold = np.mean(distances)\n",
    "    \n",
    "    #retreive the indexs of outliers in ith cluster\n",
    "    indexs_of_outlier = np.where(distances.flatten() > distance_threshold * distance_threshold_ratio)[0]\n",
    "#     indexs_of_inlier = np.where(distances.flatten() <= distance_threshold * distance_threshold_ratio)[0]\n",
    "    \n",
    "    #retrieve outliers in ith cluster by the indexs\n",
    "    outliers = X_in_ith_cluster[indexs_of_outlier]\n",
    "#     inliers = X_in_ith_cluster[indexs_of_inlier]\n",
    "    \n",
    "    #plot the outlier in ith cluster\n",
    "    plt.scatter(outliers[:,0], outliers[:,1], c='r')\n",
    "#     plt.scatter(inliers[:,0], inliers[:,1], c='pink')\n",
    "plt.title('outlier detect')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_in_ith_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid.reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawback3: Cannot Handle Non-spherical Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate non-spherical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate non-spherical data\n",
    "X, y = make_circles(n_samples=1000, factor=0.3, noise=0.1, random_state=0)\n",
    "\n",
    "#plot the data distribution. here's another way to plot graph\n",
    "plt.plot(X[:, 0], X[:, 1], 'ro')\n",
    "plt.title('data points')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X[y == 0, 0], X[y == 0, 1], 'ro')\n",
    "plt.plot(X[y == 1, 0], X[y == 1, 1], 'go')\n",
    "plt.title('ground turth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Homogeneity: {}'.format(metrics.homogeneity_score([0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 1, 1, 0, 0, 1, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run kmeans on non-spherical data\n",
    "y_pred = KMeans(n_clusters=2, random_state=170).fit_predict(X)\n",
    "\n",
    "#plot the predictions\n",
    "plt.plot(X[y_pred == 0, 0], X[y_pred == 0, 1], 'ro')\n",
    "plt.plot(X[y_pred == 1, 0], X[y_pred == 1, 1], 'go')\n",
    "\n",
    "#print the evaluations\n",
    "print('Homogeneity: {}'.format(metrics.homogeneity_score(y, y_pred)))\n",
    "print('Completeness: {}'.format(metrics.completeness_score(y, y_pred)))\n",
    "print('Mean Silhouette score: {}'.format(metrics.silhouette_score(X, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solution: Feature Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### freature transform: 將平面座標轉換成極座標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for convert Carteisan coordinates to Polar coordinates\n",
    "def cart2pol(x, y):\n",
    "    radius = np.sqrt(x**2+y**2)\n",
    "    theta = np.arctan2(y, x)\n",
    "    return radius, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate non-spherical data\n",
    "X, y=make_circles(n_samples=1000, factor=0.3, noise=0.1)\n",
    "\n",
    "X_transformed = np.zeros_like(X)\n",
    "X_transformed[:,0], X_transformed[:,1] = cart2pol(X[:,0], X[:,1])\n",
    "\n",
    "plt.plot(X_transformed[y == 0, 0], X_transformed[y == 0, 1], 'ro')\n",
    "plt.plot(X_transformed[y == 1, 0], X_transformed[y == 1, 1], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = np.zeros_like(X)\n",
    "#convert cartesian (x-y) to polar coordinates\n",
    "X_transformed[:,0], _ = cart2pol(X[:,0], X[:,1])\n",
    "\n",
    "#only use 'radius' feature to cluster\n",
    "y_pred = KMeans(n_clusters=2).fit_predict(X_transformed)\n",
    "\n",
    "plt.plot(X[y_pred == 0, 0], X[y_pred == 0, 1], 'ro')\n",
    "plt.plot(X[y_pred == 1, 0], X[y_pred == 1, 1], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = np.zeros_like(X)\n",
    "#convert cartesian (x-y) to polar coordinates\n",
    "X_transformed[:,0], X_transformed[:, 1] = cart2pol(X[:,0], X[:,1])\n",
    "# X_transformed[:, 0] *= 10\n",
    "#only use 'radius' feature to cluster\n",
    "kmeans = KMeans(n_clusters=2).fit(X_transformed)\n",
    "y_pred = kmeans.predict(X_transformed)\n",
    "\n",
    "plt.plot(X_transformed[y_pred == 0, 0], X_transformed[y_pred == 0, 1], 'ro')\n",
    "plt.plot(X_transformed[y_pred == 1, 0], X_transformed[y_pred == 1, 1], 'go')\n",
    "plt.plot(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], 'bX')\n",
    "print(kmeans.cluster_centers_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> DBSCAN </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data with 3 centers\n",
    "X, y= make_blobs(n_samples=1000,\n",
    "                n_features=2,\n",
    "                centers=3,\n",
    "                random_state=111)\n",
    "\n",
    "#standardize features to zero mean and unit variance\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "#perform DBSCAN on the data\n",
    "y_pred = DBSCAN(eps=0.3, min_samples=30).fit_predict(X)\n",
    "\n",
    "#plot the predictions\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
    "\n",
    "#print the evaluations\n",
    "print('Number of clusters: {}'.format(len(set(y_pred[np.where(y_pred !=-1)]))))\n",
    "print('Homogeneity: {}'.format(metrics.homogeneity_score(y, y_pred)))\n",
    "print('Completeness: {}'.format(metrics.completeness_score(y, y_pred)))\n",
    "print('Mean Silhouette score: {}'.format(metrics.silhouette_score(X, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate non-spherical data\n",
    "X, y=make_circles(n_samples=1000, factor=0.3, noise=0.1)\n",
    "\n",
    "#standardize features to zero mean and unit variance\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "#perform DBSCAN on the data\n",
    "y_pred = DBSCAN(eps=0.3, min_samples=10).fit_predict(X)\n",
    "#plot the predictions\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
    "plt.show()\n",
    "#print the evaluations\n",
    "print('Number of clusters: {}'.format(len(set(y_pred[np.where(y_pred !=-1)]))))\n",
    "print('Homogeneity: {}'.format(metrics.homogeneity_score(y, y_pred)))\n",
    "print('Completeness: {}'.format(metrics.completeness_score(y, y_pred)))\n",
    "print('Mean Silhouette score: {}'.format(metrics.silhouette_score(X, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "X,y = make_moons(n_samples=1000, noise=.05)\n",
    "plt.scatter(X[:,0], X[:,1], c='r')\n",
    "plt.show()\n",
    "#standardize features to zero mean and unit variance\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=2, random_state=170).fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DBSCAN(eps=0.3, min_samples=10).fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Iris dataset </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# 讀入鳶尾花資料\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#畫三維資料\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(iris_X[:,2], iris_X[:,0], iris_X[:,1], c=iris_y, marker='o')\n",
    "ax.set_xlabel('petal length')\n",
    "ax.set_ylabel('sepal length')\n",
    "ax.set_zlabel('sepal width')\n",
    "ax.set_title('ground turth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by k-means\n",
    "y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(iris_X[:,0:3])\n",
    "print('Number of clusters: {}'.format(len(set(y_pred[np.where(y_pred !=-1)]))))\n",
    "print('Homogeneity: {}'.format(metrics.homogeneity_score(iris_y, y_pred)))\n",
    "print('Completeness: {}'.format(metrics.completeness_score(iris_y, y_pred)))\n",
    "print('Mean Silhouette score: {}'.format(metrics.silhouette_score(iris_X[:,0:3], y_pred)))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(iris_X[:,2], iris_X[:,0], iris_X[:,1], c=y_pred, marker='o')\n",
    "ax.set_xlabel('petal length')\n",
    "ax.set_ylabel('sepal length')\n",
    "ax.set_zlabel('sepal width')\n",
    "ax.set_title('k-means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by dbscan\n",
    "y_pred = DBSCAN(eps=0.4, min_samples=4).fit_predict(iris_X[:,0:3])\n",
    "print('Number of clusters: {}'.format(len(set(y_pred[np.where(y_pred !=-1)]))))\n",
    "print('Homogeneity: {}'.format(metrics.homogeneity_score(iris_y, y_pred)))\n",
    "print('Completeness: {}'.format(metrics.completeness_score(iris_y, y_pred)))\n",
    "print('Mean Silhouette score: {}'.format(metrics.silhouette_score(iris_X[:,0:3], y_pred)))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(iris_X[:,2], iris_X[:,0], iris_X[:,1], c=y_pred, marker='o')\n",
    "ax.scatter(iris_X[y_pred==0,2], iris_X[y_pred==0,0], iris_X[y_pred==0,1], c='r')\n",
    "ax.scatter(iris_X[y_pred==1,2], iris_X[y_pred==1,0], iris_X[y_pred==1,1], c='g')\n",
    "ax.scatter(iris_X[y_pred==2,2], iris_X[y_pred==2,0], iris_X[y_pred==2,1], c='b')\n",
    "ax.scatter(iris_X[y_pred==-1,2], iris_X[y_pred==-1,0], iris_X[y_pred==-1,1], c='black', marker='X')\n",
    "\n",
    "ax.set_xlabel('petal length')\n",
    "ax.set_ylabel('sepal length')\n",
    "ax.set_zlabel('sepal width')\n",
    "ax.set_title('dbscan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(iris_X[:,3], iris_X[:,2], iris_X[:,1], c=iris_y, marker='o')\n",
    "ax.set_xlabel('petal width')\n",
    "ax.set_ylabel('petal length')\n",
    "ax.set_zlabel('sepal width')\n",
    "ax.set_title('ground turth')\n",
    "plt.show()\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "#for each number of clusters, perform silhouette analysis and visualize the results\n",
    "for n_clusters in range_n_clusters:\n",
    "    #perform kmeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    y_pred = kmeans.fit_predict(iris_X[:,1:4])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(iris_X[:,3], iris_X[:,2], iris_X[:,1], c=y_pred, marker='o')\n",
    "    ax.set_xlabel('petal width')\n",
    "    ax.set_ylabel('sepal length')\n",
    "    ax.set_zlabel('sepal width')\n",
    "    ax.set_title('n_clusters: '+str(n_clusters))\n",
    "    plt.show()\n",
    "    \n",
    "    #compute the cluster homogeneity and completeness\n",
    "    homogenity = metrics.homogeneity_score(iris_y, y_pred)\n",
    "    completeness = metrics.completeness_score(iris_y, y_pred)\n",
    "    print(\"k=\", n_clusters, \"homogenity: \", homogenity)\n",
    "    print(\"k=\", n_clusters, \"completeness: \", completeness)\n",
    "    #compute the silhouette coefficient for each sameple\n",
    "    s = metrics.silhouette_samples(iris_X[:,1:4], y_pred)\n",
    "    \n",
    "    #compute the mean silhouette coefficient of all the data points\n",
    "    s_mean = metrics.silhouette_score(iris_X[:,1:4], y_pred)\n",
    "    print(\"k=\", n_clusters, \"sihouette: \", s_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio for our distance threshold, controlling how many outliers we want to detect\n",
    "distance_threshold_ratio = 2.0\n",
    "#plot the prediction sane as the above\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(iris_X[:,3], iris_X[:,2], iris_X[:,1], c=iris_y, marker='o')\n",
    "\n",
    "y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(iris_X[:,1:4])\n",
    "#for each ith cluster, i=0-3(we have 3 clusters in this example)\n",
    "for i in [0, 1, 2]:\n",
    "    #retrieve the indexs of data points belong to the ith cluster\n",
    "    indexs_of_X_in_ith_cluster = np.where(y_pred == i)[0]\n",
    "                                                       \n",
    "    #retrieve the data points by the indexs\n",
    "    X_in_ith_cluster = iris_X[indexs_of_X_in_ith_cluster, 1:4]\n",
    "                                                       \n",
    "    #retrieve the centroid\n",
    "    centroid = kmeans.cluster_centers_[i]\n",
    "    \n",
    "    # compute distance between data points and the centroid\n",
    "    distances = metrics.pairwise.euclidean_distances(X_in_ith_cluster, centroid.reshape(1,-1))\n",
    "    distance_threshold = np.mean(distances)\n",
    "    \n",
    "    #retreive the indexs of outliers in ith cluster\n",
    "    indexs_of_outlier = np.where(distances.flatten() > distance_threshold * distance_threshold_ratio)[0]\n",
    "    \n",
    "    #retrieve outliers in ith cluster by the indexs\n",
    "    outliers = X_in_ith_cluster[indexs_of_outlier]\n",
    "    \n",
    "    #plot the outlier in ith cluster\n",
    "    ax.scatter(outliers[:,2], outliers[:,1], outliers[:,0], c='r', marker='X')\n",
    "\n",
    "ax.set_xlabel('petal width')\n",
    "ax.set_ylabel('petal length')\n",
    "ax.set_zlabel('sepal width')\n",
    "ax.set_title('outlier detect')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
